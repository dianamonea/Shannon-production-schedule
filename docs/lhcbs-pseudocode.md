# L-HCBS Algorithm Pseudocode

## Learning-guided Heterogeneous Conflict-Based Search

é¢å‘å¼‚æ„æ™ºèƒ½ä½“çš„å­¦ä¹ å¼•å¯¼å†²çªæœç´¢ç®—æ³•

---

## Algorithm 1: L-HCBS Main Algorithm

```
Algorithm 1: Learning-guided Heterogeneous CBS (L-HCBS)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:  G = (V, E)          // Grid map
        A = {aâ‚, ..., aâ‚™}   // Heterogeneous agents with kinematics
        s = {sâ‚, ..., sâ‚™}   // Start positions
        g = {gâ‚, ..., gâ‚™}   // Goal positions
        w â‰¥ 1               // Suboptimality bound
        GNN_Î¸               // Trained conflict predictor network

Output: Î  = {Ï€â‚, ..., Ï€â‚™}   // Collision-free paths for all agents

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1:  function L-HCBS(G, A, s, g, w, GNN_Î¸)
2:      // Initialize root node
3:      R.constraints â† âˆ…
4:      for each agent aáµ¢ âˆˆ A do
5:          R.paths[aáµ¢] â† HeterogeneousA*(G, aáµ¢, sáµ¢, gáµ¢, âˆ…)
6:      end for
7:      R.cost â† Î£áµ¢ |R.paths[aáµ¢]|
8:      R.conflicts â† DetectConflicts(R.paths, A)
9:      R.h_learned â† GNN_Î¸.Predict(R)        // Learning-guided heuristic
10:     
11:     OPEN â† {R}
12:     FOCAL â† {R}
13:     
14:     while OPEN â‰  âˆ… do
15:         // Update focal list with bounded suboptimality
16:         f_min â† min{N.cost : N âˆˆ OPEN}
17:         FOCAL â† {N âˆˆ OPEN : N.cost â‰¤ w Â· f_min}
18:         
19:         // Select node using learned priority (fail-fast strategy)
20:         N â† argmax{N.h_learned : N âˆˆ FOCAL}
21:         Remove N from OPEN and FOCAL
22:         
23:         // Check for solution
24:         if N.conflicts = âˆ… then
25:             return N.paths
26:         end if
27:         
28:         // Select conflict using GNN prediction
29:         C â† SelectConflict(N.conflicts, GNN_Î¸)
30:         
31:         // Generate child nodes (branching)
32:         for each agent aáµ¢ âˆˆ {C.agentâ‚, C.agentâ‚‚} do
33:             N' â† Copy(N)
34:             Îº â† CreateConstraint(C, aáµ¢)
35:             N'.constraints â† N'.constraints âˆª {Îº}
36:             
37:             // Replan for constrained agent
38:             N'.paths[aáµ¢] â† HeterogeneousA*(G, aáµ¢, sáµ¢, gáµ¢, N'.constraints)
39:             
40:             if N'.paths[aáµ¢] â‰  NULL then
41:                 N'.cost â† Î£â±¼ |N'.paths[aâ±¼]|
42:                 N'.conflicts â† DetectConflicts(N'.paths, A)
43:                 N'.h_learned â† GNN_Î¸.Predict(N')
44:                 Insert N' into OPEN
45:                 if N'.cost â‰¤ w Â· f_min then
46:                     Insert N' into FOCAL
47:                 end if
48:             end if
49:         end for
50:     end while
51:     
52:     return FAILURE
53: end function
```

---

## Algorithm 2: Heterogeneous Low-Level Planner

```
Algorithm 2: Heterogeneous A* (Low-Level Planner)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:  G = (V, E)          // Grid map
        a                   // Agent with kinematics K_a
        s                   // Start position
        g                   // Goal position
        Î©                   // Set of constraints

Output: Ï€                   // Kinematically feasible path

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1:  function HeterogeneousA*(G, a, s, g, Î©)
2:      OPEN â† {(s, 0)}
3:      g_score[s] â† 0
4:      f_score[s] â† Heuristic(s, g, a.type)
5:      came_from â† {}
6:      
7:      while OPEN â‰  âˆ… do
8:          current â† argmin{f_score[n] : n âˆˆ OPEN}
9:          
10:         if current.pos = g then
11:             return ReconstructPath(came_from, current)
12:         end if
13:         
14:         Remove current from OPEN
15:         
16:         // Get valid moves based on agent type
17:         neighbors â† GetKinematicNeighbors(current, a.type)
18:         
19:         for each (next_pos, next_time) âˆˆ neighbors do
20:             // Check constraints
21:             if ViolatesConstraint(a, next_pos, next_time, Î©) then
22:                 continue
23:             end if
24:             
25:             // Check kinematic feasibility
26:             if Â¬IsKinematicallyFeasible(current, next_pos, a.kinematics) then
27:                 continue
28:             end if
29:             
30:             // Compute transition cost based on agent type
31:             move_cost â† ComputeMoveCost(current, next_pos, a)
32:             tentative_g â† g_score[current] + move_cost
33:             
34:             if tentative_g < g_score[next_pos] then
35:                 came_from[next_pos] â† current
36:                 g_score[next_pos] â† tentative_g
37:                 f_score[next_pos] â† tentative_g + Heuristic(next_pos, g, a.type)
38:                 Insert (next_pos, next_time) into OPEN
39:             end if
40:         end for
41:     end while
42:     
43:     return NULL  // No path found
44: end function
```

---

## Algorithm 3: GNN Conflict Predictor

```
Algorithm 3: GNN-based Conflict Prediction
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:  N                   // CT Node with current paths
        A                   // Agent set with features
        
Output: p âˆˆ [0,1]^(nÃ—n)    // Conflict probability matrix

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1:  function GNN_Predict(N, A)
2:      // Extract node features for each agent
3:      for each agent aáµ¢ âˆˆ A do
4:          xáµ¢ â† [type_embedding(aáµ¢.type),    // Agent type (one-hot)
5:                aáµ¢.position,                 // Current position
6:                aáµ¢.goal,                     // Goal position  
7:                aáµ¢.velocity,                 // Max velocity
8:                path_length(N.paths[aáµ¢]),    // Current path length
9:                remaining_distance(aáµ¢)]      // Distance to goal
10:     end for
11:     
12:     // Extract edge features for agent pairs
13:     for each pair (aáµ¢, aâ±¼) where i < j do
14:         eáµ¢â±¼ â† [spatial_distance(aáµ¢, aâ±¼),          // Euclidean distance
15:                temporal_overlap(Ï€áµ¢, Ï€â±¼),           // Path overlap in time
16:                path_intersection_count(Ï€áµ¢, Ï€â±¼),    // Shared cells
17:                velocity_ratio(aáµ¢, aâ±¼),             // Speed difference
18:                type_compatibility(aáµ¢.type, aâ±¼.type)] // Type pair embedding
19:     end for
20:     
21:     // Graph Neural Network forward pass
22:     Hâ½â°â¾ â† X                              // Initial node embeddings
23:     
24:     for l = 1 to L do                     // L message passing layers
25:         for each agent aáµ¢ do
26:             // Aggregate neighbor messages
27:             máµ¢ â† Î£â±¼âˆˆğ’©(i) Î±(háµ¢â½Ë¡â»Â¹â¾, hâ±¼â½Ë¡â»Â¹â¾, eáµ¢â±¼) Â· Wâ‚˜ Â· hâ±¼â½Ë¡â»Â¹â¾
28:             
29:             // Update node embedding
30:             háµ¢â½Ë¡â¾ â† ReLU(Wáµ¤ Â· [háµ¢â½Ë¡â»Â¹â¾ â€– máµ¢])
31:         end for
32:     end for
33:     
34:     // Predict edge-level conflict probabilities
35:     for each pair (aáµ¢, aâ±¼) do
36:         záµ¢â±¼ â† MLP([háµ¢â½á´¸â¾ â€– hâ±¼â½á´¸â¾ â€– eáµ¢â±¼])
37:         páµ¢â±¼ â† Ïƒ(záµ¢â±¼)                       // Sigmoid activation
38:     end for
39:     
40:     return P = {páµ¢â±¼}
41: end function
```

---

## Algorithm 4: Conflict Selection

```
Algorithm 4: Learning-guided Conflict Selection
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:  C = {câ‚, ..., câ‚–}   // Set of detected conflicts
        GNN_Î¸               // Trained predictor
        
Output: c*                  // Selected conflict to resolve

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1:  function SelectConflict(C, GNN_Î¸)
2:      if |C| = 1 then
3:          return C[0]
4:      end if
5:      
6:      best_conflict â† NULL
7:      best_score â† -âˆ
8:      
9:      for each conflict c âˆˆ C do
10:         // Get predicted severity from GNN
11:         severity â† GNN_Î¸.EdgeScore(c.agentâ‚, c.agentâ‚‚)
12:         
13:         // Compute conflict impact score
14:         score â† severity Ã— ConflictTypeWeight(c.type)
15:         
16:         // Bonus for early-time conflicts (resolve sooner)
17:         score â† score + Î» Â· (1 / (c.time + 1))
18:         
19:         if score > best_score then
20:             best_score â† score
21:             best_conflict â† c
22:         end if
23:     end for
24:     
25:     return best_conflict
26: end function
```

---

## Algorithm 5: Heterogeneous Conflict Detection

```
Algorithm 5: Heterogeneous Conflict Detection
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:  Î  = {Ï€â‚, ..., Ï€â‚™}   // Paths for all agents
        A = {aâ‚, ..., aâ‚™}   // Agents with footprint info

Output: C                    // Set of conflicts

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1:  function DetectConflicts(Î , A)
2:      C â† âˆ…
3:      T_max â† max{|Ï€áµ¢| : Ï€áµ¢ âˆˆ Î }
4:      
5:      for t = 0 to T_max do
6:          for each pair (aáµ¢, aâ±¼) where i < j do
7:              posáµ¢ â† GetPosition(Ï€áµ¢, t)
8:              posâ±¼ â† GetPosition(Ï€â±¼, t)
9:              
10:             // Get agent footprints based on type
11:             Fáµ¢ â† GetFootprint(aáµ¢, posáµ¢)
12:             Fâ±¼ â† GetFootprint(aâ±¼, posâ±¼)
13:             
14:             // Vertex conflict (footprint overlap)
15:             if Fáµ¢ âˆ© Fâ±¼ â‰  âˆ… then
16:                 C â† C âˆª {VertexConflict(aáµ¢, aâ±¼, t, posáµ¢)}
17:             end if
18:             
19:             // Edge conflict (swap positions)
20:             if t > 0 then
21:                 prev_posáµ¢ â† GetPosition(Ï€áµ¢, t-1)
22:                 prev_posâ±¼ â† GetPosition(Ï€â±¼, t-1)
23:                 
24:                 if posáµ¢ = prev_posâ±¼ and posâ±¼ = prev_posáµ¢ then
25:                     C â† C âˆª {EdgeConflict(aáµ¢, aâ±¼, t, posáµ¢, posâ±¼)}
26:                 end if
27:             end if
28:             
29:             // Workspace conflict (for robots with reach)
30:             if aáµ¢.type = ROBOT or aâ±¼.type = ROBOT then
31:                 Wáµ¢ â† GetWorkspace(aáµ¢, posáµ¢)
32:                 Wâ±¼ â† GetWorkspace(aâ±¼, posâ±¼)
33:                 
34:                 if Wáµ¢ âˆ© Fâ±¼ â‰  âˆ… or Fáµ¢ âˆ© Wâ±¼ â‰  âˆ… then
35:                     C â† C âˆª {WorkspaceConflict(aáµ¢, aâ±¼, t)}
36:                 end if
37:             end if
38:         end for
39:     end for
40:     
41:     return C
42: end function
```

---

## Algorithm 6: Online Replanning

```
Algorithm 6: Dynamic Replanning with Disruptions
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Input:  Î                    // Current solution
        t_now               // Current time
        D                   // Disruption event
        
Output: Î '                  // Updated solution

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1:  function OnlineReplan(Î , t_now, D)
2:      // Identify affected agents
3:      A_affected â† GetAffectedAgents(D, Î , t_now)
4:      
5:      if D.type = MACHINE_FAILURE then
6:          // Add obstacle at failed machine location
7:          G â† G âˆª {D.location as obstacle}
8:          // Remove failed agent
9:          A â† A \ {D.agent}
10:     
11:     else if D.type = EMERGENCY_ORDER then
12:         // Add new agent with high priority
13:         a_new â† CreateAgent(D.order)
14:         a_new.priority â† HIGH
15:         A â† A âˆª {a_new}
16:         A_affected â† A_affected âˆª {a_new}
17:     
18:     else if D.type = PATH_BLOCKED then
19:         // Temporarily block cells
20:         G â† G âˆª {D.cells as temporary obstacles}
21:     end if
22:     
23:     // Preserve committed path segments
24:     Î _committed â† {}
25:     for each agent aáµ¢ âˆˆ A do
26:         Î _committed[aáµ¢] â† Ï€áµ¢[0 : t_now + T_safe]
27:     end for
28:     
29:     // Partial replanning for affected agents only
30:     s' â† {GetPosition(Ï€áµ¢, t_now + T_safe) : aáµ¢ âˆˆ A_affected}
31:     g' â† {gáµ¢ : aáµ¢ âˆˆ A_affected}
32:     
33:     // Compute constraints from unaffected agents
34:     Î©_fixed â† ComputeFixedConstraints(Î , A \ A_affected, t_now)
35:     
36:     // Replan affected agents
37:     Î _new â† L-HCBS(G, A_affected, s', g', w, GNN_Î¸, Î©_fixed)
38:     
39:     // Merge solutions
40:     Î ' â† MergePaths(Î _committed, Î _new, t_now + T_safe)
41:     
42:     return Î '
43: end function
```

---

## Theoretical Properties

### Theorem 1: Completeness
```
L-HCBS is complete: If a solution exists, L-HCBS will find it.

Proof Sketch:
- L-HCBS explores the same search space as standard CBS
- Learning only affects exploration ORDER, not the space itself
- Focal search with w â‰¥ 1 includes all optimal solutions
- Therefore, completeness is preserved from CBS â–¡
```

### Theorem 2: Bounded Suboptimality
```
For suboptimality bound w â‰¥ 1, L-HCBS returns solution Î  with:
    cost(Î ) â‰¤ w Ã— cost(Î *)

where Î * is the optimal solution.

Proof Sketch:
- Focal list contains all nodes N with f(N) â‰¤ w Ã— f_min
- Optimal solution has cost f* = f_min at some iteration
- Selected node always has f(N) â‰¤ w Ã— f*
- Solution cost bounded by w Ã— optimal â–¡
```

### Theorem 3: GNN Learning Convergence
```
Given sufficient training data, the GNN conflict predictor 
converges to the true conflict probability distribution.

Conditions:
1. Training examples i.i.d. from search distribution
2. Network has sufficient capacity
3. Learning rate follows Robbins-Monro conditions
```

---

## Complexity Analysis

| Component | Time Complexity | Space Complexity |
|-----------|----------------|------------------|
| High-level CBS | O(2^k Ã— n Ã— VÂ²) | O(2^k Ã— n Ã— V) |
| Low-level A* | O(V Ã— log V) | O(V) |
| GNN Forward | O(nÂ² Ã— d) | O(nÂ² Ã— d) |
| Conflict Detection | O(nÂ² Ã— T) | O(nÂ² Ã— T) |

Where:
- n = number of agents
- V = number of vertices in grid
- k = number of conflicts resolved
- T = maximum path length
- d = GNN hidden dimension

---

## Notation Summary

| Symbol | Description |
|--------|-------------|
| G | Grid map (V, E) |
| A | Set of agents |
| aáµ¢ | Agent i |
| sáµ¢, gáµ¢ | Start and goal of agent i |
| Ï€áµ¢ | Path of agent i |
| Î  | Solution (all paths) |
| Îº | Constraint |
| Î© | Set of constraints |
| C | Set of conflicts |
| N | Constraint tree node |
| Î¸ | GNN parameters |
| w | Suboptimality bound |
| Fáµ¢ | Footprint of agent i |
| Wáµ¢ | Workspace of agent i |

